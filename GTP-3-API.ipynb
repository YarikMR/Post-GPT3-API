{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A GPT-3 Text Classifier for Everyone\n",
    "\n",
    "In this article, I’ll show you how to use the Generative Pre-trained Transformer 3 (GPT-3) from OpenAI to build your text classifier in just a few lines of code.\n",
    "\n",
    "### What is GPT3 and why we can only use an API?\n",
    "\n",
    "GPT-3 is an autoregressive language model, created by OpenAI, that uses machine learning (Deep leering) algorithms to produce human-like text. The full version, with 75 billion parameters, produces high-quality text that can be difficult to determine wheatear or not it was written by humans (which has both risks and bene\n",
    "\n",
    "On September 22, 2020, Microsoft announced that it had licensed “exclusive” use of GPT-3 (only Microsoft has access to GPT-3’s underlying model), therefore, GPT-3 is a big black box that can only be accessed through the endpoint (API).\n",
    "\n",
    "<img src=\"OPENAI_KEY.png\" width=\"800\"/>\n",
    "\n",
    "\n",
    "### GPT 3 text classifier\n",
    "\n",
    "To have access to GPT3 you need to create an account in Opena.ai. The first time you will receive 18 USD to test the models and no credit card is needed. After creating the account, you can find the API KEYS under the option “API Keys” on the left menu.\n",
    "\n",
    "### Data pre-processing.\n",
    "\n",
    "GPT3 API expects as training data a Jsonline (Jsonl) file, consisting of a single training example with “text” and “label” fields no bigger than 150 MB.\n",
    "\n",
    "{\"text\": \"Me n him so funny...\", \"label\": \"ham\"}\n",
    "{\"text\": \"i want to grasp your pretty booty :)\", \"label\": \"ham\"}\n",
    "{\"text\": \"Sorry, I'll call later\", \"label\": \"ham\"}\n",
    "\n",
    "For this tutorial. you will build a Spam classifier using the Spam text dataset from Kaggle, which is a collection of 5157 with 13% spam. The following will pre-process the dataset to create the Jsonl file requested by GPT3’s API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_jsonl (dataset: pd.DataFrame, file_name: str):\n",
    "    with open(f'{file_name}.jsonl', 'w') as file:\n",
    "        for row in dataset.itertuples():\n",
    "            file.write(json.dumps({\"text\": row.Message,\n",
    "                                   'label': row.Category})+'\\n')\n",
    "    file.close()\n",
    "\n",
    "raw_data = pd.read_csv('SPAM text message 20170820 - Data.csv')\n",
    "train_raw, test_raw = train_test_split(raw_data, test_size=0.1)\n",
    "\n",
    "create_jsonl(train_raw, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openai # to install OpenAI API\n",
    "import openai\n",
    "\n",
    "# set credentials\n",
    "secrete_key = 'YOUR_SECRETE_KEY'\n",
    "openai.api_key = secrete_key\n",
    "\n",
    "# Upload file\n",
    "openai.File.create(file=open(\"train.jsonl\"), purpose=\"classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_id = \"YOU_FILE_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def request_classification (texts: iter, api_file: str) -> list:\n",
    "    classes = list()\n",
    "    i = 0\n",
    "    while i < len(texts):\n",
    "        try:\n",
    "            print(f'computing: {i} of {len(texts)-1}', end=\"\\r\")\n",
    "            query = openai.Classification.create(\n",
    "                file=api_file,\n",
    "                query=texts[i],\n",
    "                search_model=\"text-curie-001\",\n",
    "                model=\"text-curie-001\")\n",
    "            classes.append(query['label'])\n",
    "            i += 1\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'error {e} in doc {i}')\n",
    "            time.sleep(60)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = request_classification(test_raw['Message'].to_list(),file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "That’s all I have for today! I hope this post is useful to build your classifier with GPT-3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}